{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONv8Cyef2WH_",
    "outputId": "51b917f9-cfd7-42ad-8c20-1cef74c64d7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import yaml\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from indigo import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_MiCgvkX3BSM"
   },
   "outputs": [],
   "source": [
    "indigo = Indigo()\n",
    "indigo.setOption(\"ignore-stereochemistry-errors\", True)\n",
    "indigo.setOption(\"ignore-bad-valence\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.data.utils import split_dataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.nn.pytorch import Set2Set, NNConv\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "from indigo.ml.mpp.preprocess import mol_to_graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zc-lcC3kCm1c"
   },
   "source": [
    "**GCN for property prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Adrenergic_dataset.csv\"\n",
    "target =  \"logP\" # \"AdrA1A_PCHEMBL_VALUE\"\n",
    "smiles = \"Structure\"\n",
    "\n",
    "df = pd.read_csv(file_name)\n",
    "df = df.loc[df[target].notnull()]\n",
    "data = dict(zip(df[smiles], df[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolDataset(DGLDataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        super().__init__(name='mols')\n",
    "        \n",
    "    def process(self):\n",
    "        self.graphs = []\n",
    "        self.labels = []\n",
    "        for smiles, label in self.data.items():\n",
    "            self.graphs.append(mol_to_graph(smiles))\n",
    "            self.labels.append(label)\n",
    "\n",
    "        self.gclasses = len(self.labels)\n",
    "        self.dim_nfeats = len(self.graphs[0].ndata['atomic'][0])\n",
    "        self.dim_efeats = len(self.graphs[0].edata['ord'][0])\n",
    "        self.labels = torch.FloatTensor(self.labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.graphs[i], self.labels[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dataloaders*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    train_set, val_set, test_set = split_dataset(dataset, frac_list=None, shuffle=False, random_state=None)\n",
    "    train_loader = GraphDataLoader(dataset=train_set, shuffle=True, drop_last=False)\n",
    "    val_loader = GraphDataLoader(dataset=val_set, shuffle=True, drop_last=False)\n",
    "    test_loader = GraphDataLoader(dataset=test_set, shuffle=True, drop_last=False)\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNNGNN(nn.Module):\n",
    "\n",
    "    def __init__(self, node_in_feats, edge_in_feats, node_out_feats=64,\n",
    "                 edge_hidden_feats=128, num_step_message_passing=6):\n",
    "        super(MPNNGNN, self).__init__()\n",
    "\n",
    "        self.project_node_feats = nn.Sequential(\n",
    "            nn.Linear(node_in_feats, node_out_feats),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.num_step_message_passing = num_step_message_passing\n",
    "        edge_network = nn.Sequential(\n",
    "            nn.Linear(edge_in_feats, edge_hidden_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(edge_hidden_feats, node_out_feats * node_out_feats)\n",
    "        )\n",
    "        self.gnn_layer = NNConv(\n",
    "            in_feats=node_out_feats,\n",
    "            out_feats=node_out_feats,\n",
    "            edge_func=edge_network,\n",
    "            aggregator_type='sum'\n",
    "        )\n",
    "        self.gru = nn.GRU(node_out_feats, node_out_feats)\n",
    "\n",
    "    def forward(self, g, node_feats, edge_feats):\n",
    "        node_feats = self.project_node_feats(node_feats) \n",
    "        hidden_feats = node_feats.unsqueeze(0)           \n",
    "\n",
    "        for _ in range(self.num_step_message_passing):\n",
    "            node_feats = F.relu(self.gnn_layer(g, node_feats, edge_feats))\n",
    "            node_feats, hidden_feats = self.gru(node_feats.unsqueeze(0), hidden_feats)\n",
    "            node_feats = node_feats.squeeze(0)\n",
    "\n",
    "        return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, in_feats, hidden_feats, n_tasks, dropout=0.):\n",
    "        super(MLPRegressor, self).__init__()\n",
    "\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_feats, hidden_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_feats, n_tasks)\n",
    "        )\n",
    "\n",
    "    def forward(self, h):\n",
    "        return self.predict(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNNRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, in_node_feats, in_edge_feats, node_hidden_dim, edge_hidden_dim,\n",
    "                 num_step_message_passing, num_step_set2set, num_layer_set2set, n_tasks,\n",
    "                 regressor_hidden_feats=128, dropout=0.):\n",
    "        super(MPNNRegressor, self).__init__()\n",
    "        self.gnn = MPNNGNN(in_node_feats, in_edge_feats, node_hidden_dim,\n",
    "                           edge_hidden_dim, num_step_message_passing)\n",
    "        self.readout = Set2Set(node_hidden_dim, num_step_set2set, num_layer_set2set)\n",
    "        readout_feats = 2 * node_hidden_dim\n",
    "        self.regressor = MLPRegressor(readout_feats, regressor_hidden_feats, n_tasks, dropout)\n",
    "\n",
    "\n",
    "    def forward(self, bg, node_feats, edge_feats):\n",
    "\n",
    "        feats = self.gnn(bg, node_feats, edge_feats)\n",
    "        h_g = self.readout(bg, feats)\n",
    "\n",
    "        return self.regressor(h_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Parameters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"lr\": 3e-4,\n",
    "  \"weight_decay\": 0,\n",
    "  \"patience\": 30,\n",
    "  \"batch_size\": 128,\n",
    "  \"node_out_feats\": 64,\n",
    "  \"edge_hidden_feats\": 128,\n",
    "  \"num_step_message_passing\": 6,\n",
    "  \"num_step_set2set\": 6,\n",
    "  \"num_layer_set2set\": 3\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPNN_params = {\n",
    "    'node_hidden_dim': 64,\n",
    "    'edge_hidden_dim': 16,\n",
    "    'num_step_message_passing': 2,\n",
    "    'num_step_set2set': 3,\n",
    "    'num_layer_set2set': 2,\n",
    "    'regressor_hidden_feats': 32,\n",
    "    'dropout': 0.,\n",
    "    'n_tasks': 1\n",
    "}\n",
    "\n",
    "dataset = MolDataset(data)\n",
    "train_loader, val_loader, test_loader = load_data(dataset)\n",
    "num_epoch = 20\n",
    "model = MPNNRegressor(dataset.dim_nfeats, dataset.dim_efeats, **MPNN_params)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fcn = torch.nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epoch)):\n",
    "    losses = list()\n",
    "    for batched_graph, labels in train_loader:\n",
    "\n",
    "        node_feats = batched_graph.ndata['atomic'].float()\n",
    "        edge_feats = batched_graph.edata['ord'].float()\n",
    "        prediction = model(batched_graph, node_feats, edge_feats)\n",
    "        loss = loss_fcn(prediction, labels)\n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch: {}/{}.............'.format(epoch, num_epoch), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.mean()))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate(model, loader):\n",
    "   \n",
    "    preds = []\n",
    "    labels = []\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batched_graph, label in loader:\n",
    "           \n",
    "            node_feats = batched_graph.ndata['atomic'].float()\n",
    "            edge_feats = batched_graph.edata['ord'].float()\n",
    "            prediction = model(batched_graph, node_feats, edge_feats)\n",
    "            preds.append(float(prediction))\n",
    "            labels.append(float(label))\n",
    "\n",
    "        print(f'R2 score: {r2_score(labels, preds):.2f}')\n",
    "        print(f'MAE: {mean_absolute_error(labels, preds):.2f}')\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GMPP main training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMPPConfig(BaseModel):\n",
    "    \"\"\"A dataclass storing Graph Molecular Property Prediction model configuration parameters.\n",
    "\n",
    "    Attributes:\n",
    "        node_hidden_dim: \n",
    "        edge_hidden_dim:\n",
    "        num_step_message_passing: \n",
    "        num_step_set2set: \n",
    "        num_layer_set2set: \n",
    "        regressor_hidden_feats:\n",
    "        dropout:\n",
    "        n_tasks: \n",
    "        num_epoch:\n",
    "    \"\"\"\n",
    "    node_hidden_dim: int\n",
    "    edge_hidden_dim: int\n",
    "    num_step_message_passing: int\n",
    "    num_step_set2set: int\n",
    "    num_layer_set2set: int\n",
    "    regressor_hidden_feats: int\n",
    "    dropout: int\n",
    "    n_tasks: int\n",
    "    num_epoch: int\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(file_name: str, config_class: BaseModel):\n",
    "    with open(file_name, \"r\") as f:\n",
    "        data = yaml.safe_load(f)\n",
    "        return config_class(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    dataset_filename: str,  # or file path?\n",
    "    smiles_column: str,\n",
    "    target_column: str,\n",
    "    config_filename: str\n",
    "):\n",
    "    df = pd.read_csv(dataset_filename)\n",
    "    df = df.loc[df[target_column].notnull()]\n",
    "    data = dict(zip(df[smiles_column], df[target_column]))\n",
    "\n",
    "    config = load_config(config_filename, GMPPConfig)\n",
    "    dataset = MolDataset(data)\n",
    "    train_loader, val_loader, test_loader = load_data(dataset)\n",
    "    \n",
    "    model = MPNNRegressor(dataset.dim_nfeats, dataset.dim_efeats, **config.dict())\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fcn = torch.nn.SmoothL1Loss()\n",
    "    \n",
    "    for epoch in tqdm(range(config.num_epoch)):\n",
    "        losses = list()\n",
    "        for batched_graph, labels in train_loader:\n",
    "            node_feats = batched_graph.ndata['atomic'].float()\n",
    "            edge_feats = batched_graph.edata['ord'].float()\n",
    "            prediction = model(batched_graph, node_feats, edge_feats)\n",
    "            loss = loss_fcn(prediction, labels)\n",
    "            losses.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print('Epoch: {}/{}.............'.format(epoch, num_epoch), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.mean()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"Adrenergic_dataset.csv\", \"Structure\", \"logP\", \"MPNN.yml\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of mol-to-g.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
